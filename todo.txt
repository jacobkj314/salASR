- Finetuning the models in ROAR-style
	WIP

- Test the off-the-shelf model with different r values and compare the random masking vs top/bottom-r masking scores 
	WIP

- !vocode the new spectrograms


-graded/translucent mask to better represent the disribution of different saliency scores


-try different formulas for saliency (beyond just magnitude of gradient)


- it could just be out of domain
-maybe using more bins would help? I know you can do this in hf but idk how rn
    -maybe this for part II of the project


-try models larger than "tiny"
   DONE

-use model.forward() to use teacher forcing to see in what proportion of steps is the predicted token the correct next token
        DONE
    -check whether there is currently an imbalance across different frequency bins
