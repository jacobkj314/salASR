INFO:root:Using GPU: cuda
INFO:root:Namespace(info=True, logFile=None, cacheDir='/scratch/general/vast/u0403624/huggingface_cache', dataset='librispeech_asr', model='whisper', size='large', numSamples=500, numEpochs=3, batchSize=16, learningRate=2e-05, outputDir='/scratch/general/vast/u0403624/cs6966/salASR/models/-1/', seed=13, r=-1.0)
WARNING:datasets.builder:No config specified, defaulting to: librispeech_asr/all
WARNING:datasets.builder:No config specified, defaulting to: librispeech_asr/all
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/1500 [00:00<?, ?it/s]There seems to be not a single sample in your epoch_iterator, stopping training at step 480! This is expected if you're using an IterableDataset and set num_steps (1500) higher than the number of available samples.
                                          0%|          | 0/1500 [08:43<?, ?it/s]Could not locate the best model at /scratch/general/vast/u0403624/cs6966/salASR/models/-1/checkpoint-416/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.
                                          0%|          | 0/1500 [09:28<?, ?it/s]{'eval_loss': 0.778670072555542, 'eval_wer': 38.10725552050473, 'eval_runtime': 384.9646, 'eval_samples_per_second': 1.299, 'eval_steps_per_second': 0.083, 'epoch': 14.02}
{'train_runtime': 568.522, 'train_samples_per_second': 42.215, 'train_steps_per_second': 2.638, 'train_loss': 0.0, 'epoch': 14.02}
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u0403624/salASR/finetuneWhisper.py", line 341, in <module>
    main()
  File "/uufs/chpc.utah.edu/common/home/u0403624/salASR/finetuneWhisper.py", line 338, in main
    trainer.train(resume_from_checkpoint=True)
  File "/uufs/chpc.utah.edu/common/home/u0403624/miniconda3/envs/finetuneWhisperEnv/lib/python3.9/site-packages/transformers/trainer.py", line 1555, in train
    return inner_training_loop(
  File "/uufs/chpc.utah.edu/common/home/u0403624/miniconda3/envs/finetuneWhisperEnv/lib/python3.9/site-packages/transformers/trainer.py", line 1990, in _inner_training_loop
    checkpoints_sorted = self._sorted_checkpoints(use_mtime=False, output_dir=run_dir)
  File "/uufs/chpc.utah.edu/common/home/u0403624/miniconda3/envs/finetuneWhisperEnv/lib/python3.9/site-packages/transformers/trainer.py", line 2905, in _sorted_checkpoints
    best_model_index = checkpoints_sorted.index(str(Path(self.state.best_model_checkpoint)))
ValueError: '/scratch/general/vast/u0403624/cs6966/salASR/models/-1/checkpoint-416' is not in list
  0%|          | 0/1500 [09:28<?, ?it/s]
